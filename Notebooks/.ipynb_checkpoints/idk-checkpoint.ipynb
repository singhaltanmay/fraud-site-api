{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-12-11T04:00:37.872681Z",
     "iopub.status.busy": "2023-12-11T04:00:37.871774Z",
     "iopub.status.idle": "2023-12-11T04:00:58.880510Z",
     "shell.execute_reply": "2023-12-11T04:00:58.879317Z",
     "shell.execute_reply.started": "2023-12-11T04:00:37.872628Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T04:00:58.883526Z",
     "iopub.status.busy": "2023-12-11T04:00:58.882813Z",
     "iopub.status.idle": "2023-12-11T04:00:59.346741Z",
     "shell.execute_reply": "2023-12-11T04:00:59.345363Z",
     "shell.execute_reply.started": "2023-12-11T04:00:58.883486Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/kaggle/input/spam-classification-for-basic-nlp/Spam Email raw text for NLP.csv', index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T04:00:59.349213Z",
     "iopub.status.busy": "2023-12-11T04:00:59.348785Z",
     "iopub.status.idle": "2023-12-11T04:00:59.362515Z",
     "shell.execute_reply": "2023-12-11T04:00:59.361162Z",
     "shell.execute_reply.started": "2023-12-11T04:00:59.349180Z"
    }
   },
   "outputs": [],
   "source": [
    "msgs = df.MESSAGE.astype('str').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T04:00:59.368108Z",
     "iopub.status.busy": "2023-12-11T04:00:59.367606Z",
     "iopub.status.idle": "2023-12-11T04:00:59.383920Z",
     "shell.execute_reply": "2023-12-11T04:00:59.382622Z",
     "shell.execute_reply.started": "2023-12-11T04:00:59.368063Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5796, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = df.CATEGORY.values\n",
    "y = np.zeros((len(labels), 2))\n",
    "for i in range(len(labels)):\n",
    "    y[i, labels[i]]=1\n",
    "    \n",
    "labels = y\n",
    "\n",
    "\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T04:00:59.386213Z",
     "iopub.status.busy": "2023-12-11T04:00:59.385824Z",
     "iopub.status.idle": "2023-12-11T04:00:59.399453Z",
     "shell.execute_reply": "2023-12-11T04:00:59.397991Z",
     "shell.execute_reply.started": "2023-12-11T04:00:59.386169Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5796,) (5796, 2)\n"
     ]
    }
   ],
   "source": [
    "print(msgs.shape, labels.shape)\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(msgs, labels, shuffle=True, random_state=0, train_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T04:06:18.166475Z",
     "iopub.status.busy": "2023-12-11T04:06:18.165949Z",
     "iopub.status.idle": "2023-12-11T04:06:20.362861Z",
     "shell.execute_reply": "2023-12-11T04:06:20.361241Z",
     "shell.execute_reply.started": "2023-12-11T04:06:18.166438Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=30000)\n",
    "tokenizer.fit_on_texts(Xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T04:06:21.359751Z",
     "iopub.status.busy": "2023-12-11T04:06:21.359314Z",
     "iopub.status.idle": "2023-12-11T04:06:22.949745Z",
     "shell.execute_reply": "2023-12-11T04:06:22.948623Z",
     "shell.execute_reply.started": "2023-12-11T04:06:21.359716Z"
    }
   },
   "outputs": [],
   "source": [
    "Xtokens = tokenizer.texts_to_sequences(Xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T04:06:23.788318Z",
     "iopub.status.busy": "2023-12-11T04:06:23.787895Z",
     "iopub.status.idle": "2023-12-11T04:06:23.796081Z",
     "shell.execute_reply": "2023-12-11T04:06:23.794739Z",
     "shell.execute_reply.started": "2023-12-11T04:06:23.788281Z"
    }
   },
   "outputs": [],
   "source": [
    "maxlen = np.max(list(map(lambda x : len(x), Xtokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T04:40:36.152537Z",
     "iopub.status.busy": "2023-12-11T04:40:36.152105Z",
     "iopub.status.idle": "2023-12-11T04:40:36.161600Z",
     "shell.execute_reply": "2023-12-11T04:40:36.160009Z",
     "shell.execute_reply.started": "2023-12-11T04:40:36.152505Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13006"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T04:06:27.267754Z",
     "iopub.status.busy": "2023-12-11T04:06:27.267283Z",
     "iopub.status.idle": "2023-12-11T04:06:27.276170Z",
     "shell.execute_reply": "2023-12-11T04:06:27.274878Z",
     "shell.execute_reply.started": "2023-12-11T04:06:27.267716Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68, 262)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Xtokens[0]), len(Xtokens[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T05:44:07.227081Z",
     "iopub.status.busy": "2023-12-11T05:44:07.226551Z",
     "iopub.status.idle": "2023-12-11T05:44:07.236448Z",
     "shell.execute_reply": "2023-12-11T05:44:07.234955Z",
     "shell.execute_reply.started": "2023-12-11T05:44:07.227043Z"
    }
   },
   "outputs": [],
   "source": [
    "class CustomDataset():\n",
    "    def __init__(self, X, y, pad_sequences, maxlen=13006):\n",
    "        self.msgs = X\n",
    "        self.labels = y\n",
    "        self.maxlen = maxlen\n",
    "        self.pad_sequences = pad_sequences\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.msgs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        msg = [self.msgs[idx]]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        return {\n",
    "            'msg' : torch.tensor(msg).long(),\n",
    "            'target' : torch.tensor(label).float()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T05:44:44.901309Z",
     "iopub.status.busy": "2023-12-11T05:44:44.900850Z",
     "iopub.status.idle": "2023-12-11T05:44:45.134562Z",
     "shell.execute_reply": "2023-12-11T05:44:45.133099Z",
     "shell.execute_reply.started": "2023-12-11T05:44:44.901276Z"
    }
   },
   "outputs": [],
   "source": [
    "Xtrainseq = np.array(Xtrainseq)\n",
    "train_dataset = CustomDataset(Xtrainseq, Ytrain, pad_sequences, maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T05:44:47.081449Z",
     "iopub.status.busy": "2023-12-11T05:44:47.080966Z",
     "iopub.status.idle": "2023-12-11T05:44:47.095866Z",
     "shell.execute_reply": "2023-12-11T05:44:47.094587Z",
     "shell.execute_reply.started": "2023-12-11T05:44:47.081415Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 13006])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]['msg'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T04:41:26.470772Z",
     "iopub.status.busy": "2023-12-11T04:41:26.470364Z",
     "iopub.status.idle": "2023-12-11T04:41:27.129339Z",
     "shell.execute_reply": "2023-12-11T04:41:27.128350Z",
     "shell.execute_reply.started": "2023-12-11T04:41:26.470740Z"
    }
   },
   "outputs": [],
   "source": [
    "Xtesttokens = tokenizer.texts_to_sequences(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T05:45:15.752599Z",
     "iopub.status.busy": "2023-12-11T05:45:15.752107Z",
     "iopub.status.idle": "2023-12-11T05:45:15.780432Z",
     "shell.execute_reply": "2023-12-11T05:45:15.778777Z",
     "shell.execute_reply.started": "2023-12-11T05:45:15.752565Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1  \n",
       "1.0  0.0    2723\n",
       "0.0  1.0    1334\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(Ytrain).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T05:45:20.163769Z",
     "iopub.status.busy": "2023-12-11T05:45:20.163263Z",
     "iopub.status.idle": "2023-12-11T05:45:20.170820Z",
     "shell.execute_reply": "2023-12-11T05:45:20.169364Z",
     "shell.execute_reply.started": "2023-12-11T05:45:20.163731Z"
    }
   },
   "outputs": [],
   "source": [
    "test_dataset = CustomDataset(Xtestseq, Ytest, pad_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T05:45:21.528951Z",
     "iopub.status.busy": "2023-12-11T05:45:21.528483Z",
     "iopub.status.idle": "2023-12-11T05:45:21.544359Z",
     "shell.execute_reply": "2023-12-11T05:45:21.542511Z",
     "shell.execute_reply.started": "2023-12-11T05:45:21.528916Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 13006])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[0]['msg'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T05:45:26.456037Z",
     "iopub.status.busy": "2023-12-11T05:45:26.455355Z",
     "iopub.status.idle": "2023-12-11T05:45:26.463835Z",
     "shell.execute_reply": "2023-12-11T05:45:26.462087Z",
     "shell.execute_reply.started": "2023-12-11T05:45:26.455982Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T07:14:58.049191Z",
     "iopub.status.busy": "2023-12-11T07:14:58.048441Z",
     "iopub.status.idle": "2023-12-11T07:17:08.155532Z",
     "shell.execute_reply": "2023-12-11T07:17:08.153477Z",
     "shell.execute_reply.started": "2023-12-11T07:14:58.049142Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7b7c4f259360>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/torchsummary/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7b7c4f259660>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/torchsummary/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7b7c4f259900>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/torchsummary/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7b7c4f259ab0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/torchsummary/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7b7c4f259c60>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/torchsummary/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement torchsummary (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for torchsummary\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T07:37:05.089252Z",
     "iopub.status.busy": "2023-12-11T07:37:05.088109Z",
     "iopub.status.idle": "2023-12-11T07:37:05.100167Z",
     "shell.execute_reply": "2023-12-11T07:37:05.098303Z",
     "shell.execute_reply.started": "2023-12-11T07:37:05.089190Z"
    }
   },
   "outputs": [],
   "source": [
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self, num_words, embedding_size):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.embedding_size = embedding_size\n",
    "        self.embed = nn.Embedding(num_words, embedding_size, max_norm=True)\n",
    "        layers = [\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(embedding_size*13006, 2),\n",
    "            nn.Sigmoid()\n",
    "        ]\n",
    "        self.model = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x=self.embed(x)\n",
    "        out=self.model(x)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T07:31:47.991638Z",
     "iopub.status.busy": "2023-12-11T07:31:47.991166Z",
     "iopub.status.idle": "2023-12-11T07:31:48.001738Z",
     "shell.execute_reply": "2023-12-11T07:31:47.999890Z",
     "shell.execute_reply.started": "2023-12-11T07:31:47.991596Z"
    }
   },
   "outputs": [],
   "source": [
    "def trainer(train_loader, model, optimizer, criterion):\n",
    "    model.train()\n",
    "    it_loss = 0\n",
    "    counter = 0\n",
    "    for data in train_loader:\n",
    "        msgs = data['msg']\n",
    "        targets = data['target']\n",
    "        out = model(msgs)\n",
    "        print(out)\n",
    "        #print(out)\n",
    "        #targets = targets.reshape((targets.shape[0], 1))\n",
    "        #print(targets)\n",
    "        loss = criterion(out, targets)\n",
    "        #print(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        it_loss+=loss.item()*msgs.shape[0]\n",
    "        counter+=msgs.shape[0]\n",
    "        \n",
    "    return it_loss/counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T07:31:49.213224Z",
     "iopub.status.busy": "2023-12-11T07:31:49.212738Z",
     "iopub.status.idle": "2023-12-11T07:31:49.222817Z",
     "shell.execute_reply": "2023-12-11T07:31:49.221414Z",
     "shell.execute_reply.started": "2023-12-11T07:31:49.213187Z"
    }
   },
   "outputs": [],
   "source": [
    "def tester(test_loader, model, criterion):\n",
    "    model.eval()\n",
    "    it_loss=0\n",
    "    counter=0\n",
    "    for data in test_loader:\n",
    "        msgs = data['msg']\n",
    "        targets = data['target']\n",
    "        with torch.no_grad():\n",
    "            out = model(msgs)\n",
    "            #targets = targets.reshape((targets.shape[0], 1))\n",
    "            loss = criterion(out, targets)\n",
    "            \n",
    "            it_loss+=loss.item()*msgs.shape[0]\n",
    "            counter+=msgs.shape[0]\n",
    "        \n",
    "    return it_loss/counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T07:37:09.519463Z",
     "iopub.status.busy": "2023-12-11T07:37:09.518773Z",
     "iopub.status.idle": "2023-12-11T07:37:09.589970Z",
     "shell.execute_reply": "2023-12-11T07:37:09.588572Z",
     "shell.execute_reply.started": "2023-12-11T07:37:09.519402Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleModel(\n",
       "  (embed): Embedding(30000, 64, max_norm=True)\n",
       "  (model): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=832384, out_features=2, bias=True)\n",
       "    (2): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SimpleModel(30000, 64)\n",
    "epochs = 10\n",
    "lr = 1e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=0.9)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T07:37:09.973994Z",
     "iopub.status.busy": "2023-12-11T07:37:09.973507Z",
     "iopub.status.idle": "2023-12-11T07:37:29.382471Z",
     "shell.execute_reply": "2023-12-11T07:37:29.380735Z",
     "shell.execute_reply.started": "2023-12-11T07:37:09.973951Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Began iteration 1\n",
      "tensor([[0.5168, 0.4748],\n",
      "        [0.5185, 0.4799],\n",
      "        [0.5195, 0.4788],\n",
      "        [0.5205, 0.4732],\n",
      "        [0.5181, 0.4754],\n",
      "        [0.5136, 0.4786],\n",
      "        [0.5193, 0.4741],\n",
      "        [0.5222, 0.4804],\n",
      "        [0.5248, 0.4836],\n",
      "        [0.5170, 0.4770],\n",
      "        [0.5195, 0.4825],\n",
      "        [0.5194, 0.4761],\n",
      "        [0.5178, 0.4754],\n",
      "        [0.5167, 0.4755],\n",
      "        [0.5187, 0.4621],\n",
      "        [0.5230, 0.4812],\n",
      "        [0.5192, 0.4745],\n",
      "        [0.5189, 0.4850],\n",
      "        [0.5081, 0.4877],\n",
      "        [0.5193, 0.4758],\n",
      "        [0.5177, 0.4746],\n",
      "        [0.5177, 0.4761],\n",
      "        [0.5225, 0.4679],\n",
      "        [0.5190, 0.4754],\n",
      "        [0.5218, 0.4813],\n",
      "        [0.5396, 0.4722],\n",
      "        [0.5175, 0.4758],\n",
      "        [0.5162, 0.4749],\n",
      "        [0.5174, 0.4738],\n",
      "        [0.5202, 0.4748],\n",
      "        [0.5194, 0.4803],\n",
      "        [0.5196, 0.4793]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[1.0000e+00, 6.1480e-36],\n",
      "        [1.0000e+00, 5.0573e-36],\n",
      "        [1.0000e+00, 1.9612e-34],\n",
      "        [1.0000e+00, 3.7075e-36],\n",
      "        [1.0000e+00, 6.5466e-34],\n",
      "        [1.0000e+00, 5.6264e-36],\n",
      "        [1.0000e+00, 1.3085e-35],\n",
      "        [1.0000e+00, 2.1575e-33],\n",
      "        [1.0000e+00, 1.5830e-34],\n",
      "        [1.0000e+00, 3.1969e-36],\n",
      "        [1.0000e+00, 3.1614e-36],\n",
      "        [1.0000e+00, 3.1880e-36],\n",
      "        [1.0000e+00, 8.5186e-36],\n",
      "        [1.0000e+00, 1.0893e-34],\n",
      "        [1.0000e+00, 1.3017e-35],\n",
      "        [1.0000e+00, 5.8014e-36],\n",
      "        [1.0000e+00, 1.9980e-35],\n",
      "        [1.0000e+00, 3.4833e-36],\n",
      "        [1.0000e+00, 3.2104e-36],\n",
      "        [1.0000e+00, 1.3656e-35],\n",
      "        [1.0000e+00, 3.1541e-36],\n",
      "        [1.0000e+00, 1.0297e-35],\n",
      "        [1.0000e+00, 1.3846e-32],\n",
      "        [1.0000e+00, 3.2028e-36],\n",
      "        [1.0000e+00, 2.7066e-33],\n",
      "        [1.0000e+00, 3.4463e-35],\n",
      "        [1.0000e+00, 6.6881e-36],\n",
      "        [1.0000e+00, 3.5327e-36],\n",
      "        [1.0000e+00, 3.1564e-36],\n",
      "        [1.0000e+00, 2.0609e-32],\n",
      "        [1.0000e+00, 3.1716e-36],\n",
      "        [1.0000e+00, 1.8806e-35]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [3.7882e-13, 1.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]], grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[373], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mBegan iteration \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     test_loss \u001b[38;5;241m=\u001b[39m tester(test_loader, model, criterion)\n\u001b[1;32m      8\u001b[0m     train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n",
      "Cell \u001b[0;32mIn[355], line 5\u001b[0m, in \u001b[0;36mtrainer\u001b[0;34m(train_loader, model, optimizer, criterion)\u001b[0m\n\u001b[1;32m      3\u001b[0m it_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      4\u001b[0m counter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m      6\u001b[0m     msgs \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmsg\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      7\u001b[0m     targets \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    677\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 678\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    680\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[155], line 16\u001b[0m, in \u001b[0;36mCustomDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     12\u001b[0m msg \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmsgs[idx]]\n\u001b[1;32m     13\u001b[0m label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels[idx]\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m---> 16\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmsg\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mlong(),\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m : torch\u001b[38;5;241m.\u001b[39mtensor(label)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m     18\u001b[0m }\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_losses=[]\n",
    "test_losses=[]\n",
    "best_loss=np.inf\n",
    "for epoch in range(epochs):\n",
    "    print(f'\\nBegan iteration {epoch+1}')\n",
    "    train_loss = trainer(train_loader, model, optimizer, criterion)\n",
    "    test_loss = tester(test_loader, model, criterion)\n",
    "    train_losses.append(train_loss)\n",
    "    test_losses.append(test_loss)\n",
    "    #scheduler.step()\n",
    "    print(f'Test Loss : {test_loss}')\n",
    "    if test_loss<best_loss:\n",
    "        best_loss=test_loss\n",
    "        dic={\n",
    "            'model':model.state_dict()\n",
    "        }\n",
    "        torch.save(dic, './Bestmodel.model')\n",
    "        print('Improved and saved the model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T05:08:49.200008Z",
     "iopub.status.busy": "2023-12-11T05:08:49.199471Z",
     "iopub.status.idle": "2023-12-11T05:08:55.239575Z",
     "shell.execute_reply": "2023-12-11T05:08:55.238208Z",
     "shell.execute_reply.started": "2023-12-11T05:08:49.199964Z"
    }
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "pred=[]\n",
    "for data in test_loader:\n",
    "    msgs = data['msg']\n",
    "    with torch.no_grad():\n",
    "        out = model(msgs)\n",
    "        pred.append(out.to('cpu').numpy())\n",
    "        \n",
    "pred = np.concatenate(pred)    \n",
    "#pred = pred.argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T05:09:00.276760Z",
     "iopub.status.busy": "2023-12-11T05:09:00.276353Z",
     "iopub.status.idle": "2023-12-11T05:09:00.287001Z",
     "shell.execute_reply": "2023-12-11T05:09:00.285429Z",
     "shell.execute_reply.started": "2023-12-11T05:09:00.276729Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T05:11:16.089652Z",
     "iopub.status.busy": "2023-12-11T05:11:16.089197Z",
     "iopub.status.idle": "2023-12-11T05:11:16.103319Z",
     "shell.execute_reply": "2023-12-11T05:11:16.101819Z",
     "shell.execute_reply.started": "2023-12-11T05:11:16.089618Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1  \n",
       "1.0  0.0    1739\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(pred).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T04:06:56.159926Z",
     "iopub.status.busy": "2023-12-11T04:06:56.159489Z",
     "iopub.status.idle": "2023-12-11T04:06:56.401514Z",
     "shell.execute_reply": "2023-12-11T04:06:56.399917Z",
     "shell.execute_reply.started": "2023-12-11T04:06:56.159890Z"
    }
   },
   "outputs": [],
   "source": [
    "Xtrainseq = pad_sequences(Xtokens, maxlen=maxlen, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T04:06:57.552855Z",
     "iopub.status.busy": "2023-12-11T04:06:57.552330Z",
     "iopub.status.idle": "2023-12-11T04:06:57.689224Z",
     "shell.execute_reply": "2023-12-11T04:06:57.687823Z",
     "shell.execute_reply.started": "2023-12-11T04:06:57.552814Z"
    }
   },
   "outputs": [],
   "source": [
    "Xtestseq = pad_sequences(Xtesttokens, maxlen=maxlen, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T04:06:59.141639Z",
     "iopub.status.busy": "2023-12-11T04:06:59.141141Z",
     "iopub.status.idle": "2023-12-11T04:06:59.150201Z",
     "shell.execute_reply": "2023-12-11T04:06:59.148868Z",
     "shell.execute_reply.started": "2023-12-11T04:06:59.141601Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4057, 13006)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrainseq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T04:07:00.105526Z",
     "iopub.status.busy": "2023-12-11T04:07:00.105126Z",
     "iopub.status.idle": "2023-12-11T04:07:00.114779Z",
     "shell.execute_reply": "2023-12-11T04:07:00.112929Z",
     "shell.execute_reply.started": "2023-12-11T04:07:00.105493Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1739, 13006)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtestseq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T04:18:19.892094Z",
     "iopub.status.busy": "2023-12-11T04:18:19.891620Z",
     "iopub.status.idle": "2023-12-11T04:18:20.000326Z",
     "shell.execute_reply": "2023-12-11T04:18:19.997220Z",
     "shell.execute_reply.started": "2023-12-11T04:18:19.892059Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 13006)]           0         \n",
      "                                                                 \n",
      " embedding_3 (Embedding)     (None, 13006, 64)         1920000   \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 832384)            0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 1664770   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3584770 (13.67 MB)\n",
      "Trainable params: 3584770 (13.67 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "inputs = tf.keras.Input(shape=(13006, ))\n",
    "embedding = tf.keras.layers.Embedding( \n",
    "    input_dim = 30000,\n",
    "    output_dim = 64\n",
    ")(inputs)\n",
    "flatten = tf.keras.layers.Flatten()(embedding)\n",
    "outputs = tf.keras.layers.Dense(2, activation='sigmoid')(flatten)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss = 'binary_crossentropy',\n",
    "    metrics = [\n",
    "        'accuracy',\n",
    "        tf.keras.metrics.AUC(name='auc')\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T04:18:23.945478Z",
     "iopub.status.busy": "2023-12-11T04:18:23.944965Z",
     "iopub.status.idle": "2023-12-11T04:20:32.701849Z",
     "shell.execute_reply": "2023-12-11T04:20:32.700858Z",
     "shell.execute_reply.started": "2023-12-11T04:18:23.945442Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "102/102 [==============================] - 21s 184ms/step - loss: 0.7031 - accuracy: 0.8133 - auc: 0.8521 - val_loss: 0.1090 - val_accuracy: 0.9569 - val_auc: 0.9935\n",
      "Epoch 2/100\n",
      "102/102 [==============================] - 18s 172ms/step - loss: 0.0487 - accuracy: 0.9883 - auc: 0.9995 - val_loss: 0.0439 - val_accuracy: 0.9901 - val_auc: 0.9979\n",
      "Epoch 3/100\n",
      "102/102 [==============================] - 18s 181ms/step - loss: 0.0155 - accuracy: 0.9978 - auc: 1.0000 - val_loss: 0.0374 - val_accuracy: 0.9901 - val_auc: 0.9978\n",
      "Epoch 4/100\n",
      "102/102 [==============================] - 18s 180ms/step - loss: 0.0080 - accuracy: 0.9991 - auc: 1.0000 - val_loss: 0.0348 - val_accuracy: 0.9901 - val_auc: 0.9978\n",
      "Epoch 5/100\n",
      "102/102 [==============================] - 18s 181ms/step - loss: 0.0051 - accuracy: 0.9994 - auc: 1.0000 - val_loss: 0.0356 - val_accuracy: 0.9889 - val_auc: 0.9969\n",
      "Epoch 6/100\n",
      "102/102 [==============================] - 17s 170ms/step - loss: 0.0034 - accuracy: 0.9994 - auc: 1.0000 - val_loss: 0.0350 - val_accuracy: 0.9889 - val_auc: 0.9970\n",
      "Epoch 7/100\n",
      "102/102 [==============================] - 17s 170ms/step - loss: 0.0025 - accuracy: 0.9997 - auc: 1.0000 - val_loss: 0.0361 - val_accuracy: 0.9889 - val_auc: 0.9970\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(Xtrainseq, Ytrain, validation_split=0.2, batch_size=32, epochs=100,\n",
    "                   callbacks=[\n",
    "                       tf.keras.callbacks.EarlyStopping(\n",
    "                       monitor = 'val_loss',\n",
    "                       patience=3,\n",
    "                       restore_best_weights=True)\n",
    "                   ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T04:27:04.664940Z",
     "iopub.status.busy": "2023-12-11T04:27:04.664522Z",
     "iopub.status.idle": "2023-12-11T04:27:09.994589Z",
     "shell.execute_reply": "2023-12-11T04:27:09.993293Z",
     "shell.execute_reply.started": "2023-12-11T04:27:04.664909Z"
    }
   },
   "outputs": [],
   "source": [
    "results = model.evaluate(Xtestseq, Ytest, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T05:12:53.074737Z",
     "iopub.status.busy": "2023-12-11T05:12:53.074287Z",
     "iopub.status.idle": "2023-12-11T05:12:53.081298Z",
     "shell.execute_reply": "2023-12-11T05:12:53.080186Z",
     "shell.execute_reply.started": "2023-12-11T05:12:53.074703Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss : 0.029011981561779976\n",
      "accuracy : 99.48245882987976%\n",
      "auc : 0.998275637626648\n"
     ]
    }
   ],
   "source": [
    "print(f'val_loss : {results[0]}\\naccuracy : {results[1]*100}%\\nauc : {results[2]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T04:30:06.415682Z",
     "iopub.status.busy": "2023-12-11T04:30:06.415196Z",
     "iopub.status.idle": "2023-12-11T04:30:06.676213Z",
     "shell.execute_reply": "2023-12-11T04:30:06.674801Z",
     "shell.execute_reply.started": "2023-12-11T04:30:06.415644Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('./kerasModel.model', 'wb') as handle:\n",
    "    pickle.dump(model, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T04:31:18.426634Z",
     "iopub.status.busy": "2023-12-11T04:31:18.425368Z",
     "iopub.status.idle": "2023-12-11T04:31:18.562113Z",
     "shell.execute_reply": "2023-12-11T04:31:18.560643Z",
     "shell.execute_reply.started": "2023-12-11T04:31:18.426580Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('./kerasModel.model', 'wb') as handle:\n",
    "    pickle.dump(model, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T04:32:29.689522Z",
     "iopub.status.busy": "2023-12-11T04:32:29.689098Z",
     "iopub.status.idle": "2023-12-11T04:32:29.697744Z",
     "shell.execute_reply": "2023-12-11T04:32:29.695975Z",
     "shell.execute_reply.started": "2023-12-11T04:32:29.689484Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('./tuner.tuner', 'wb') as handle:\n",
    "    pickle.dump({ \n",
    "        'maxlen':13006,\n",
    "        'num_words' : 30000\n",
    "    }, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T04:33:33.162360Z",
     "iopub.status.busy": "2023-12-11T04:33:33.161957Z",
     "iopub.status.idle": "2023-12-11T04:33:38.516656Z",
     "shell.execute_reply": "2023-12-11T04:33:38.515249Z",
     "shell.execute_reply.started": "2023-12-11T04:33:33.162328Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 4s 63ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(Xtestseq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T04:33:42.829391Z",
     "iopub.status.busy": "2023-12-11T04:33:42.827890Z",
     "iopub.status.idle": "2023-12-11T04:33:42.837381Z",
     "shell.execute_reply": "2023-12-11T04:33:42.836367Z",
     "shell.execute_reply.started": "2023-12-11T04:33:42.829328Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.4426785e-04, 9.9984843e-01],\n",
       "       [7.6759284e-07, 9.9999923e-01],\n",
       "       [9.9859142e-01, 1.3892701e-03],\n",
       "       ...,\n",
       "       [9.9996293e-01, 3.8821665e-05],\n",
       "       [9.9363053e-01, 6.3473103e-03],\n",
       "       [9.9924135e-01, 7.5421837e-04]], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T04:34:29.893853Z",
     "iopub.status.busy": "2023-12-11T04:34:29.893358Z",
     "iopub.status.idle": "2023-12-11T04:34:29.903191Z",
     "shell.execute_reply": "2023-12-11T04:34:29.901889Z",
     "shell.execute_reply.started": "2023-12-11T04:34:29.893814Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0min_features\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mout_features\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbias\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Applies a linear transformation to the incoming data: :math:`y = xA^T + b`\n",
       "\n",
       "This module supports :ref:`TensorFloat32<tf32_on_ampere>`.\n",
       "\n",
       "On certain ROCm devices, when using float16 inputs this module will use :ref:`different precision<fp16_on_mi200>` for backward.\n",
       "\n",
       "Args:\n",
       "    in_features: size of each input sample\n",
       "    out_features: size of each output sample\n",
       "    bias: If set to ``False``, the layer will not learn an additive bias.\n",
       "        Default: ``True``\n",
       "\n",
       "Shape:\n",
       "    - Input: :math:`(*, H_{in})` where :math:`*` means any number of\n",
       "      dimensions including none and :math:`H_{in} = \\text{in\\_features}`.\n",
       "    - Output: :math:`(*, H_{out})` where all but the last dimension\n",
       "      are the same shape as the input and :math:`H_{out} = \\text{out\\_features}`.\n",
       "\n",
       "Attributes:\n",
       "    weight: the learnable weights of the module of shape\n",
       "        :math:`(\\text{out\\_features}, \\text{in\\_features})`. The values are\n",
       "        initialized from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})`, where\n",
       "        :math:`k = \\frac{1}{\\text{in\\_features}}`\n",
       "    bias:   the learnable bias of the module of shape :math:`(\\text{out\\_features})`.\n",
       "            If :attr:`bias` is ``True``, the values are initialized from\n",
       "            :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n",
       "            :math:`k = \\frac{1}{\\text{in\\_features}}`\n",
       "\n",
       "Examples::\n",
       "\n",
       "    >>> m = nn.Linear(20, 30)\n",
       "    >>> input = torch.randn(128, 20)\n",
       "    >>> output = m(input)\n",
       "    >>> print(output.size())\n",
       "    torch.Size([128, 30])\n",
       "\u001b[0;31mInit docstring:\u001b[0m Initializes internal Module state, shared by both nn.Module and ScriptModule.\n",
       "\u001b[0;31mFile:\u001b[0m           /opt/conda/lib/python3.10/site-packages/torch/nn/modules/linear.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     NonDynamicallyQuantizableLinear, LazyLinear, Linear, LinearBn1d, Linear"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?nn.Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T05:33:19.927638Z",
     "iopub.status.busy": "2023-12-11T05:33:19.927219Z",
     "iopub.status.idle": "2023-12-11T05:33:19.967595Z",
     "shell.execute_reply": "2023-12-11T05:33:19.966363Z",
     "shell.execute_reply.started": "2023-12-11T05:33:19.927608Z"
    }
   },
   "outputs": [],
   "source": [
    "embed = nn.Embedding(30000, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T06:21:26.027747Z",
     "iopub.status.busy": "2023-12-11T06:21:26.027303Z",
     "iopub.status.idle": "2023-12-11T06:21:26.036228Z",
     "shell.execute_reply": "2023-12-11T06:21:26.034860Z",
     "shell.execute_reply.started": "2023-12-11T06:21:26.027709Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m      \u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mType:\u001b[0m           Embedding\n",
       "\u001b[0;31mString form:\u001b[0m    Embedding(30000, 100)\n",
       "\u001b[0;31mFile:\u001b[0m           /opt/conda/lib/python3.10/site-packages/torch/nn/modules/sparse.py\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "A simple lookup table that stores embeddings of a fixed dictionary and size.\n",
       "\n",
       "This module is often used to store word embeddings and retrieve them using indices.\n",
       "The input to the module is a list of indices, and the output is the corresponding\n",
       "word embeddings.\n",
       "\n",
       "Args:\n",
       "    num_embeddings (int): size of the dictionary of embeddings\n",
       "    embedding_dim (int): the size of each embedding vector\n",
       "    padding_idx (int, optional): If specified, the entries at :attr:`padding_idx` do not contribute to the gradient;\n",
       "                                 therefore, the embedding vector at :attr:`padding_idx` is not updated during training,\n",
       "                                 i.e. it remains as a fixed \"pad\". For a newly constructed Embedding,\n",
       "                                 the embedding vector at :attr:`padding_idx` will default to all zeros,\n",
       "                                 but can be updated to another value to be used as the padding vector.\n",
       "    max_norm (float, optional): If given, each embedding vector with norm larger than :attr:`max_norm`\n",
       "                                is renormalized to have norm :attr:`max_norm`.\n",
       "    norm_type (float, optional): The p of the p-norm to compute for the :attr:`max_norm` option. Default ``2``.\n",
       "    scale_grad_by_freq (bool, optional): If given, this will scale gradients by the inverse of frequency of\n",
       "                                            the words in the mini-batch. Default ``False``.\n",
       "    sparse (bool, optional): If ``True``, gradient w.r.t. :attr:`weight` matrix will be a sparse tensor.\n",
       "                             See Notes for more details regarding sparse gradients.\n",
       "\n",
       "Attributes:\n",
       "    weight (Tensor): the learnable weights of the module of shape (num_embeddings, embedding_dim)\n",
       "                     initialized from :math:`\\mathcal{N}(0, 1)`\n",
       "\n",
       "Shape:\n",
       "    - Input: :math:`(*)`, IntTensor or LongTensor of arbitrary shape containing the indices to extract\n",
       "    - Output: :math:`(*, H)`, where `*` is the input shape and :math:`H=\\text{embedding\\_dim}`\n",
       "\n",
       ".. note::\n",
       "    Keep in mind that only a limited number of optimizers support\n",
       "    sparse gradients: currently it's :class:`optim.SGD` (`CUDA` and `CPU`),\n",
       "    :class:`optim.SparseAdam` (`CUDA` and `CPU`) and :class:`optim.Adagrad` (`CPU`)\n",
       "\n",
       ".. note::\n",
       "    When :attr:`max_norm` is not ``None``, :class:`Embedding`'s forward method will modify the\n",
       "    :attr:`weight` tensor in-place. Since tensors needed for gradient computations cannot be\n",
       "    modified in-place, performing a differentiable operation on ``Embedding.weight`` before\n",
       "    calling :class:`Embedding`'s forward method requires cloning ``Embedding.weight`` when\n",
       "    :attr:`max_norm` is not ``None``. For example::\n",
       "\n",
       "        n, d, m = 3, 5, 7\n",
       "        embedding = nn.Embedding(n, d, max_norm=True)\n",
       "        W = torch.randn((m, d), requires_grad=True)\n",
       "        idx = torch.tensor([1, 2])\n",
       "        a = embedding.weight.clone() @ W.t()  # weight must be cloned for this to be differentiable\n",
       "        b = embedding(idx) @ W.t()  # modifies weight in-place\n",
       "        out = (a.unsqueeze(0) + b.unsqueeze(1))\n",
       "        loss = out.sigmoid().prod()\n",
       "        loss.backward()\n",
       "\n",
       "Examples::\n",
       "\n",
       "    >>> # an Embedding module containing 10 tensors of size 3\n",
       "    >>> embedding = nn.Embedding(10, 3)\n",
       "    >>> # a batch of 2 samples of 4 indices each\n",
       "    >>> input = torch.LongTensor([[1, 2, 4, 5], [4, 3, 2, 9]])\n",
       "    >>> # xdoctest: +IGNORE_WANT(\"non-deterministic\")\n",
       "    >>> embedding(input)\n",
       "    tensor([[[-0.0251, -1.6902,  0.7172],\n",
       "             [-0.6431,  0.0748,  0.6969],\n",
       "             [ 1.4970,  1.3448, -0.9685],\n",
       "             [-0.3677, -2.7265, -0.1685]],\n",
       "\n",
       "            [[ 1.4970,  1.3448, -0.9685],\n",
       "             [ 0.4362, -0.4004,  0.9400],\n",
       "             [-0.6431,  0.0748,  0.6969],\n",
       "             [ 0.9124, -2.3616,  1.1151]]])\n",
       "\n",
       "\n",
       "    >>> # example with padding_idx\n",
       "    >>> embedding = nn.Embedding(10, 3, padding_idx=0)\n",
       "    >>> input = torch.LongTensor([[0, 2, 0, 5]])\n",
       "    >>> embedding(input)\n",
       "    tensor([[[ 0.0000,  0.0000,  0.0000],\n",
       "             [ 0.1535, -2.0309,  0.9315],\n",
       "             [ 0.0000,  0.0000,  0.0000],\n",
       "             [-0.1655,  0.9897,  0.0635]]])\n",
       "\n",
       "    >>> # example of changing `pad` vector\n",
       "    >>> padding_idx = 0\n",
       "    >>> embedding = nn.Embedding(3, 3, padding_idx=padding_idx)\n",
       "    >>> embedding.weight\n",
       "    Parameter containing:\n",
       "    tensor([[ 0.0000,  0.0000,  0.0000],\n",
       "            [-0.7895, -0.7089, -0.0364],\n",
       "            [ 0.6778,  0.5803,  0.2678]], requires_grad=True)\n",
       "    >>> with torch.no_grad():\n",
       "    ...     embedding.weight[padding_idx] = torch.ones(3)\n",
       "    >>> embedding.weight\n",
       "    Parameter containing:\n",
       "    tensor([[ 1.0000,  1.0000,  1.0000],\n",
       "            [-0.7895, -0.7089, -0.0364],\n",
       "            [ 0.6778,  0.5803,  0.2678]], requires_grad=True)\n",
       "\u001b[0;31mInit docstring:\u001b[0m Initializes internal Module state, shared by both nn.Module and ScriptModule."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T05:33:20.140882Z",
     "iopub.status.busy": "2023-12-11T05:33:20.140405Z",
     "iopub.status.idle": "2023-12-11T05:33:20.146099Z",
     "shell.execute_reply": "2023-12-11T05:33:20.144886Z",
     "shell.execute_reply.started": "2023-12-11T05:33:20.140845Z"
    }
   },
   "outputs": [],
   "source": [
    "embed = embed.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T05:40:30.410010Z",
     "iopub.status.busy": "2023-12-11T05:40:30.408729Z",
     "iopub.status.idle": "2023-12-11T05:40:30.416736Z",
     "shell.execute_reply": "2023-12-11T05:40:30.415468Z",
     "shell.execute_reply.started": "2023-12-11T05:40:30.409962Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4057, 13006)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrainseq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T05:53:01.257775Z",
     "iopub.status.busy": "2023-12-11T05:53:01.257238Z",
     "iopub.status.idle": "2023-12-11T05:53:01.480274Z",
     "shell.execute_reply": "2023-12-11T05:53:01.478733Z",
     "shell.execute_reply.started": "2023-12-11T05:53:01.257737Z"
    }
   },
   "outputs": [],
   "source": [
    "out1 = embed(torch.tensor(Xtrainseq[33:65, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T06:20:54.708975Z",
     "iopub.status.busy": "2023-12-11T06:20:54.708402Z",
     "iopub.status.idle": "2023-12-11T06:20:54.721301Z",
     "shell.execute_reply": "2023-12-11T06:20:54.720165Z",
     "shell.execute_reply.started": "2023-12-11T06:20:54.708933Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.7669, -0.7957,  1.1804,  ...,  1.8686,  0.0808, -0.3324],\n",
       "        [ 1.0841,  1.7009,  0.5163,  ...,  0.8654, -0.3148, -0.7324],\n",
       "        [-1.6359, -1.1111, -0.7735,  ..., -1.7328,  1.7643, -0.2569],\n",
       "        ...,\n",
       "        [-0.0657, -0.5851, -1.7279,  ..., -0.8922,  1.3751,  0.3412],\n",
       "        [-0.0657, -0.5851, -1.7279,  ..., -0.8922,  1.3751,  0.3412],\n",
       "        [-0.0657, -0.5851, -1.7279,  ..., -0.8922,  1.3751,  0.3412]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out1[1,...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T05:41:35.508709Z",
     "iopub.status.busy": "2023-12-11T05:41:35.508300Z",
     "iopub.status.idle": "2023-12-11T05:41:35.513910Z",
     "shell.execute_reply": "2023-12-11T05:41:35.513031Z",
     "shell.execute_reply.started": "2023-12-11T05:41:35.508676Z"
    }
   },
   "outputs": [],
   "source": [
    "ff = nn.Flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T05:53:21.563088Z",
     "iopub.status.busy": "2023-12-11T05:53:21.562651Z",
     "iopub.status.idle": "2023-12-11T05:53:21.569314Z",
     "shell.execute_reply": "2023-12-11T05:53:21.567903Z",
     "shell.execute_reply.started": "2023-12-11T05:53:21.563054Z"
    }
   },
   "outputs": [],
   "source": [
    "out2 = ff(out1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T05:53:38.691129Z",
     "iopub.status.busy": "2023-12-11T05:53:38.689594Z",
     "iopub.status.idle": "2023-12-11T05:53:38.702483Z",
     "shell.execute_reply": "2023-12-11T05:53:38.700407Z",
     "shell.execute_reply.started": "2023-12-11T05:53:38.691051Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4139,  0.6069,  0.4648,  ..., -0.8922,  1.3751,  0.3412],\n",
       "        [ 1.7669, -0.7957,  1.1804,  ..., -0.8922,  1.3751,  0.3412],\n",
       "        [-0.2385, -0.4048, -0.3093,  ..., -0.8922,  1.3751,  0.3412],\n",
       "        ...,\n",
       "        [ 0.5774,  0.0971, -0.7322,  ..., -0.8922,  1.3751,  0.3412],\n",
       "        [-1.2598, -0.5892, -0.5497,  ..., -0.8922,  1.3751,  0.3412],\n",
       "        [-1.0076,  1.1179,  0.0841,  ..., -0.8922,  1.3751,  0.3412]],\n",
       "       grad_fn=<ReshapeAliasBackward0>)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T05:42:02.797692Z",
     "iopub.status.busy": "2023-12-11T05:42:02.797238Z",
     "iopub.status.idle": "2023-12-11T05:42:02.808247Z",
     "shell.execute_reply": "2023-12-11T05:42:02.806308Z",
     "shell.execute_reply.started": "2023-12-11T05:42:02.797657Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1300600])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T05:42:18.382165Z",
     "iopub.status.busy": "2023-12-11T05:42:18.380636Z",
     "iopub.status.idle": "2023-12-11T05:42:18.429165Z",
     "shell.execute_reply": "2023-12-11T05:42:18.428064Z",
     "shell.execute_reply.started": "2023-12-11T05:42:18.382104Z"
    }
   },
   "outputs": [],
   "source": [
    "fc=nn.Linear(1300600, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T05:53:44.119638Z",
     "iopub.status.busy": "2023-12-11T05:53:44.118932Z",
     "iopub.status.idle": "2023-12-11T05:53:44.170735Z",
     "shell.execute_reply": "2023-12-11T05:53:44.169354Z",
     "shell.execute_reply.started": "2023-12-11T05:53:44.119577Z"
    }
   },
   "outputs": [],
   "source": [
    "out3=fc(out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T05:53:46.330058Z",
     "iopub.status.busy": "2023-12-11T05:53:46.329536Z",
     "iopub.status.idle": "2023-12-11T05:53:46.342297Z",
     "shell.execute_reply": "2023-12-11T05:53:46.340680Z",
     "shell.execute_reply.started": "2023-12-11T05:53:46.330016Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6469, -0.6326],\n",
       "        [-0.4534, -0.6711],\n",
       "        [-0.5873, -0.6424],\n",
       "        [-0.4347, -0.9044],\n",
       "        [-0.6438, -0.6197],\n",
       "        [-0.5014, -0.6910],\n",
       "        [-0.1932, -0.3577],\n",
       "        [-0.5487, -0.5274],\n",
       "        [-0.5428, -0.6081],\n",
       "        [-0.6678, -0.6045],\n",
       "        [-0.5750, -0.6395],\n",
       "        [-0.4702, -0.7442],\n",
       "        [-0.4611, -0.4308],\n",
       "        [-0.4572, -0.6268],\n",
       "        [-0.6093, -0.7042],\n",
       "        [-0.3012, -0.6205],\n",
       "        [-0.4687, -0.6614],\n",
       "        [-0.5496, -0.6504],\n",
       "        [-0.4975, -0.6318],\n",
       "        [-0.6055, -0.6654],\n",
       "        [-0.5533, -0.6290],\n",
       "        [-0.6643, -0.5860],\n",
       "        [-0.5819, -0.6686],\n",
       "        [-0.0346, -0.3917],\n",
       "        [-0.4988, -0.8273],\n",
       "        [-0.6047, -0.5693],\n",
       "        [-0.5663, -0.6921],\n",
       "        [-0.5819, -0.6199],\n",
       "        [-0.3686, -0.6514],\n",
       "        [-0.5357, -0.6136],\n",
       "        [-0.4437, -0.6501],\n",
       "        [-0.4342, -0.7104]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T05:53:53.335475Z",
     "iopub.status.busy": "2023-12-11T05:53:53.335076Z",
     "iopub.status.idle": "2023-12-11T05:53:53.342505Z",
     "shell.execute_reply": "2023-12-11T05:53:53.341552Z",
     "shell.execute_reply.started": "2023-12-11T05:53:53.335444Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 2])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T05:53:58.571147Z",
     "iopub.status.busy": "2023-12-11T05:53:58.570632Z",
     "iopub.status.idle": "2023-12-11T05:53:58.579299Z",
     "shell.execute_reply": "2023-12-11T05:53:58.577381Z",
     "shell.execute_reply.started": "2023-12-11T05:53:58.571111Z"
    }
   },
   "outputs": [],
   "source": [
    "out4 = nn.Softmax(dim=1)(out3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T05:53:59.383304Z",
     "iopub.status.busy": "2023-12-11T05:53:59.381858Z",
     "iopub.status.idle": "2023-12-11T05:53:59.395677Z",
     "shell.execute_reply": "2023-12-11T05:53:59.394200Z",
     "shell.execute_reply.started": "2023-12-11T05:53:59.383243Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4964, 0.5036],\n",
       "        [0.5542, 0.4458],\n",
       "        [0.5137, 0.4863],\n",
       "        [0.6153, 0.3847],\n",
       "        [0.4940, 0.5060],\n",
       "        [0.5473, 0.4527],\n",
       "        [0.5410, 0.4590],\n",
       "        [0.4947, 0.5053],\n",
       "        [0.5163, 0.4837],\n",
       "        [0.4842, 0.5158],\n",
       "        [0.5161, 0.4839],\n",
       "        [0.5681, 0.4319],\n",
       "        [0.4924, 0.5076],\n",
       "        [0.5423, 0.4577],\n",
       "        [0.5237, 0.4763],\n",
       "        [0.5791, 0.4209],\n",
       "        [0.5480, 0.4520],\n",
       "        [0.5252, 0.4748],\n",
       "        [0.5335, 0.4665],\n",
       "        [0.5150, 0.4850],\n",
       "        [0.5189, 0.4811],\n",
       "        [0.4804, 0.5196],\n",
       "        [0.5217, 0.4783],\n",
       "        [0.5883, 0.4117],\n",
       "        [0.5814, 0.4186],\n",
       "        [0.4911, 0.5089],\n",
       "        [0.5314, 0.4686],\n",
       "        [0.5095, 0.4905],\n",
       "        [0.5703, 0.4297],\n",
       "        [0.5195, 0.4805],\n",
       "        [0.5514, 0.4486],\n",
       "        [0.5686, 0.4314]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T07:39:04.972262Z",
     "iopub.status.busy": "2023-12-11T07:39:04.971513Z",
     "iopub.status.idle": "2023-12-11T07:39:05.050101Z",
     "shell.execute_reply": "2023-12-11T07:39:05.047970Z",
     "shell.execute_reply.started": "2023-12-11T07:39:04.972188Z"
    }
   },
   "outputs": [],
   "source": [
    "trial = nn.Sequential(*[\n",
    "    nn.Embedding(30000, 100, max_norm=True).requires_grad_(True),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(1300600, 2),\n",
    "    nn.Sigmoid()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T07:39:06.921994Z",
     "iopub.status.busy": "2023-12-11T07:39:06.920670Z",
     "iopub.status.idle": "2023-12-11T07:39:06.929116Z",
     "shell.execute_reply": "2023-12-11T07:39:06.927235Z",
     "shell.execute_reply.started": "2023-12-11T07:39:06.921937Z"
    }
   },
   "outputs": [],
   "source": [
    "ada = torch.optim.SGD(trial.parameters(), lr=0.001)\n",
    "cri = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T06:35:51.815829Z",
     "iopub.status.busy": "2023-12-11T06:35:51.814960Z",
     "iopub.status.idle": "2023-12-11T06:35:51.940561Z",
     "shell.execute_reply": "2023-12-11T06:35:51.939509Z",
     "shell.execute_reply.started": "2023-12-11T06:35:51.815756Z"
    }
   },
   "outputs": [],
   "source": [
    "#1st mini batch\n",
    "out = trial(torch.tensor(Xtrainseq[:32, :]))\n",
    "out = nn.Sigmoid()(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T06:35:52.897232Z",
     "iopub.status.busy": "2023-12-11T06:35:52.896761Z",
     "iopub.status.idle": "2023-12-11T06:35:52.907728Z",
     "shell.execute_reply": "2023-12-11T06:35:52.906303Z",
     "shell.execute_reply.started": "2023-12-11T06:35:52.897195Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5019, 0.5001],\n",
       "        [0.5066, 0.4969],\n",
       "        [0.5035, 0.4990],\n",
       "        [0.5022, 0.4967],\n",
       "        [0.5047, 0.4988],\n",
       "        [0.4991, 0.4994],\n",
       "        [0.4980, 0.4944],\n",
       "        [0.5063, 0.4988],\n",
       "        [0.5029, 0.5068],\n",
       "        [0.5039, 0.4971],\n",
       "        [0.5049, 0.4983],\n",
       "        [0.5025, 0.4972],\n",
       "        [0.5035, 0.4961],\n",
       "        [0.5023, 0.4959],\n",
       "        [0.4973, 0.4985],\n",
       "        [0.4931, 0.4929],\n",
       "        [0.5046, 0.4965],\n",
       "        [0.5019, 0.5012],\n",
       "        [0.4962, 0.4939],\n",
       "        [0.5030, 0.4984],\n",
       "        [0.5046, 0.4979],\n",
       "        [0.5044, 0.4981],\n",
       "        [0.5024, 0.5017],\n",
       "        [0.5008, 0.4988],\n",
       "        [0.5015, 0.5000],\n",
       "        [0.5022, 0.5099],\n",
       "        [0.5042, 0.4985],\n",
       "        [0.5034, 0.4976],\n",
       "        [0.5039, 0.4975],\n",
       "        [0.5038, 0.5002],\n",
       "        [0.5052, 0.4992],\n",
       "        [0.5101, 0.4997]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T06:35:59.966013Z",
     "iopub.status.busy": "2023-12-11T06:35:59.965498Z",
     "iopub.status.idle": "2023-12-11T06:35:59.973390Z",
     "shell.execute_reply": "2023-12-11T06:35:59.971730Z",
     "shell.execute_reply.started": "2023-12-11T06:35:59.965973Z"
    }
   },
   "outputs": [],
   "source": [
    "l = cri(out, torch.tensor(Ytest[:32,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T06:36:01.044645Z",
     "iopub.status.busy": "2023-12-11T06:36:01.044211Z",
     "iopub.status.idle": "2023-12-11T06:36:01.055359Z",
     "shell.execute_reply": "2023-12-11T06:36:01.053573Z",
     "shell.execute_reply.started": "2023-12-11T06:36:01.044610Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6922, dtype=torch.float64, grad_fn=<DivBackward1>)"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T06:36:07.785158Z",
     "iopub.status.busy": "2023-12-11T06:36:07.784649Z",
     "iopub.status.idle": "2023-12-11T06:36:08.137143Z",
     "shell.execute_reply": "2023-12-11T06:36:08.135561Z",
     "shell.execute_reply.started": "2023-12-11T06:36:07.785122Z"
    }
   },
   "outputs": [],
   "source": [
    "l.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T06:36:09.119391Z",
     "iopub.status.busy": "2023-12-11T06:36:09.118891Z",
     "iopub.status.idle": "2023-12-11T06:36:09.128492Z",
     "shell.execute_reply": "2023-12-11T06:36:09.127071Z",
     "shell.execute_reply.started": "2023-12-11T06:36:09.119354Z"
    }
   },
   "outputs": [],
   "source": [
    "ada.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T06:36:11.891318Z",
     "iopub.status.busy": "2023-12-11T06:36:11.890916Z",
     "iopub.status.idle": "2023-12-11T06:36:12.029506Z",
     "shell.execute_reply": "2023-12-11T06:36:12.027920Z",
     "shell.execute_reply.started": "2023-12-11T06:36:11.891287Z"
    }
   },
   "outputs": [],
   "source": [
    "#2nd mini batch\n",
    "out = trial(torch.tensor(Xtrainseq[32:64, :]))\n",
    "\n",
    "out = nn.Sigmoid()(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T06:36:13.319963Z",
     "iopub.status.busy": "2023-12-11T06:36:13.319455Z",
     "iopub.status.idle": "2023-12-11T06:36:13.331404Z",
     "shell.execute_reply": "2023-12-11T06:36:13.330086Z",
     "shell.execute_reply.started": "2023-12-11T06:36:13.319925Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7306, 0.2755],\n",
       "        [0.7291, 0.2734],\n",
       "        [0.7177, 0.2826],\n",
       "        [0.7274, 0.2728],\n",
       "        [0.7142, 0.2821],\n",
       "        [0.7257, 0.2756],\n",
       "        [0.7264, 0.2728],\n",
       "        [0.7131, 0.2881],\n",
       "        [0.7178, 0.2835],\n",
       "        [0.7283, 0.2735],\n",
       "        [0.7284, 0.2717],\n",
       "        [0.7292, 0.2723],\n",
       "        [0.7271, 0.2736],\n",
       "        [0.7218, 0.2812],\n",
       "        [0.7264, 0.2783],\n",
       "        [0.7270, 0.2708],\n",
       "        [0.7259, 0.2769],\n",
       "        [0.7277, 0.2732],\n",
       "        [0.7282, 0.2717],\n",
       "        [0.7250, 0.2776],\n",
       "        [0.7298, 0.2723],\n",
       "        [0.7266, 0.2739],\n",
       "        [0.7120, 0.2922],\n",
       "        [0.7292, 0.2722],\n",
       "        [0.7186, 0.2889],\n",
       "        [0.7233, 0.2784],\n",
       "        [0.7274, 0.2750],\n",
       "        [0.7279, 0.2723],\n",
       "        [0.7290, 0.2721],\n",
       "        [0.7104, 0.2831],\n",
       "        [0.7302, 0.2715],\n",
       "        [0.7285, 0.2748]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out #the fuck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T06:36:18.798777Z",
     "iopub.status.busy": "2023-12-11T06:36:18.798317Z",
     "iopub.status.idle": "2023-12-11T06:36:18.805506Z",
     "shell.execute_reply": "2023-12-11T06:36:18.803782Z",
     "shell.execute_reply.started": "2023-12-11T06:36:18.798742Z"
    }
   },
   "outputs": [],
   "source": [
    "l=cri(out, torch.tensor(Ytest[32:64,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T06:36:19.887165Z",
     "iopub.status.busy": "2023-12-11T06:36:19.886594Z",
     "iopub.status.idle": "2023-12-11T06:36:19.897344Z",
     "shell.execute_reply": "2023-12-11T06:36:19.895992Z",
     "shell.execute_reply.started": "2023-12-11T06:36:19.887124Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6182, dtype=torch.float64, grad_fn=<DivBackward1>)"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T06:36:21.006204Z",
     "iopub.status.busy": "2023-12-11T06:36:21.004715Z",
     "iopub.status.idle": "2023-12-11T06:36:21.221644Z",
     "shell.execute_reply": "2023-12-11T06:36:21.220465Z",
     "shell.execute_reply.started": "2023-12-11T06:36:21.006145Z"
    }
   },
   "outputs": [],
   "source": [
    "l.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T06:36:22.647499Z",
     "iopub.status.busy": "2023-12-11T06:36:22.647063Z",
     "iopub.status.idle": "2023-12-11T06:36:22.659684Z",
     "shell.execute_reply": "2023-12-11T06:36:22.658289Z",
     "shell.execute_reply.started": "2023-12-11T06:36:22.647464Z"
    }
   },
   "outputs": [],
   "source": [
    "ada.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T06:36:23.308698Z",
     "iopub.status.busy": "2023-12-11T06:36:23.308279Z",
     "iopub.status.idle": "2023-12-11T06:36:23.441406Z",
     "shell.execute_reply": "2023-12-11T06:36:23.439767Z",
     "shell.execute_reply.started": "2023-12-11T06:36:23.308657Z"
    }
   },
   "outputs": [],
   "source": [
    "#3rd mini batch\n",
    "out = trial(torch.tensor(Xtrainseq[64:96, :]))\n",
    "\n",
    "out = nn.Sigmoid()(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T06:36:24.079459Z",
     "iopub.status.busy": "2023-12-11T06:36:24.078980Z",
     "iopub.status.idle": "2023-12-11T06:36:24.090405Z",
     "shell.execute_reply": "2023-12-11T06:36:24.089276Z",
     "shell.execute_reply.started": "2023-12-11T06:36:24.079416Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8997, 0.1000],\n",
       "        [0.8736, 0.1220],\n",
       "        [0.9037, 0.0972],\n",
       "        [0.9026, 0.0978],\n",
       "        [0.9031, 0.0969],\n",
       "        [0.9035, 0.0972],\n",
       "        [0.8986, 0.1021],\n",
       "        [0.9027, 0.0972],\n",
       "        [0.9036, 0.0972],\n",
       "        [0.9029, 0.0960],\n",
       "        [0.9035, 0.0964],\n",
       "        [0.9032, 0.0965],\n",
       "        [0.9032, 0.0973],\n",
       "        [0.9034, 0.0973],\n",
       "        [0.8977, 0.1015],\n",
       "        [0.8833, 0.1182],\n",
       "        [0.9040, 0.0962],\n",
       "        [0.9038, 0.0969],\n",
       "        [0.9036, 0.0971],\n",
       "        [0.9035, 0.0979],\n",
       "        [0.9025, 0.0987],\n",
       "        [0.9034, 0.0965],\n",
       "        [0.8957, 0.1044],\n",
       "        [0.9037, 0.0970],\n",
       "        [0.9036, 0.0969],\n",
       "        [0.9038, 0.0963],\n",
       "        [0.9028, 0.0965],\n",
       "        [0.8973, 0.1045],\n",
       "        [0.9012, 0.1012],\n",
       "        [0.9025, 0.0979],\n",
       "        [0.9040, 0.0966],\n",
       "        [0.8940, 0.1040]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T06:36:29.338934Z",
     "iopub.status.busy": "2023-12-11T06:36:29.338496Z",
     "iopub.status.idle": "2023-12-11T06:36:29.345920Z",
     "shell.execute_reply": "2023-12-11T06:36:29.344468Z",
     "shell.execute_reply.started": "2023-12-11T06:36:29.338900Z"
    }
   },
   "outputs": [],
   "source": [
    "l = cri(out, torch.tensor(Ytest[64:96,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T06:36:30.205506Z",
     "iopub.status.busy": "2023-12-11T06:36:30.204806Z",
     "iopub.status.idle": "2023-12-11T06:36:30.216054Z",
     "shell.execute_reply": "2023-12-11T06:36:30.214275Z",
     "shell.execute_reply.started": "2023-12-11T06:36:30.205451Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7729, dtype=torch.float64, grad_fn=<DivBackward1>)"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T06:36:33.811584Z",
     "iopub.status.busy": "2023-12-11T06:36:33.810960Z",
     "iopub.status.idle": "2023-12-11T06:36:34.046337Z",
     "shell.execute_reply": "2023-12-11T06:36:34.045236Z",
     "shell.execute_reply.started": "2023-12-11T06:36:33.811548Z"
    }
   },
   "outputs": [],
   "source": [
    "l.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T06:36:34.514699Z",
     "iopub.status.busy": "2023-12-11T06:36:34.513953Z",
     "iopub.status.idle": "2023-12-11T06:36:34.523645Z",
     "shell.execute_reply": "2023-12-11T06:36:34.522400Z",
     "shell.execute_reply.started": "2023-12-11T06:36:34.514658Z"
    }
   },
   "outputs": [],
   "source": [
    "ada.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T06:36:35.252556Z",
     "iopub.status.busy": "2023-12-11T06:36:35.251608Z",
     "iopub.status.idle": "2023-12-11T06:36:35.381579Z",
     "shell.execute_reply": "2023-12-11T06:36:35.379862Z",
     "shell.execute_reply.started": "2023-12-11T06:36:35.252508Z"
    }
   },
   "outputs": [],
   "source": [
    "#4th\n",
    "out = trial(torch.tensor(Xtrainseq[96:128, :]))\n",
    "\n",
    "out = nn.Sigmoid()(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T06:35:15.421298Z",
     "iopub.status.busy": "2023-12-11T06:35:15.420827Z",
     "iopub.status.idle": "2023-12-11T06:35:15.432682Z",
     "shell.execute_reply": "2023-12-11T06:35:15.431167Z",
     "shell.execute_reply.started": "2023-12-11T06:35:15.421263Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9631, 0.0343],\n",
       "        [0.9631, 0.0344],\n",
       "        [0.9621, 0.0343],\n",
       "        [0.9621, 0.0348],\n",
       "        [0.9623, 0.0349],\n",
       "        [0.9627, 0.0348],\n",
       "        [0.9617, 0.0353],\n",
       "        [0.9630, 0.0345],\n",
       "        [0.9610, 0.0358],\n",
       "        [0.9617, 0.0354],\n",
       "        [0.9627, 0.0343],\n",
       "        [0.9619, 0.0350],\n",
       "        [0.9629, 0.0342],\n",
       "        [0.9622, 0.0353],\n",
       "        [0.9588, 0.0385],\n",
       "        [0.9617, 0.0349],\n",
       "        [0.9624, 0.0342],\n",
       "        [0.9624, 0.0351],\n",
       "        [0.9628, 0.0349],\n",
       "        [0.9625, 0.0346],\n",
       "        [0.9629, 0.0344],\n",
       "        [0.9542, 0.0433],\n",
       "        [0.9617, 0.0356],\n",
       "        [0.9574, 0.0403],\n",
       "        [0.9621, 0.0346],\n",
       "        [0.9619, 0.0349],\n",
       "        [0.9604, 0.0359],\n",
       "        [0.9617, 0.0352],\n",
       "        [0.9630, 0.0343],\n",
       "        [0.9618, 0.0360],\n",
       "        [0.9625, 0.0345],\n",
       "        [0.9624, 0.0348]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T07:39:12.963949Z",
     "iopub.status.busy": "2023-12-11T07:39:12.963371Z",
     "iopub.status.idle": "2023-12-11T07:39:12.973495Z",
     "shell.execute_reply": "2023-12-11T07:39:12.971618Z",
     "shell.execute_reply.started": "2023-12-11T07:39:12.963905Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Embedding(30000, 100, max_norm=True)\n",
       "  (1): Flatten(start_dim=1, end_dim=-1)\n",
       "  (2): Linear(in_features=1300600, out_features=2, bias=True)\n",
       "  (3): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T07:39:49.464118Z",
     "iopub.status.busy": "2023-12-11T07:39:49.463470Z",
     "iopub.status.idle": "2023-12-11T07:40:14.573368Z",
     "shell.execute_reply": "2023-12-11T07:40:14.572260Z",
     "shell.execute_reply.started": "2023-12-11T07:39:49.464062Z"
    }
   },
   "outputs": [],
   "source": [
    "out1 = trial(torch.tensor(Xtrainseq[:,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T07:42:33.419627Z",
     "iopub.status.busy": "2023-12-11T07:42:33.419003Z",
     "iopub.status.idle": "2023-12-11T07:42:33.428680Z",
     "shell.execute_reply": "2023-12-11T07:42:33.426992Z",
     "shell.execute_reply.started": "2023-12-11T07:42:33.419587Z"
    }
   },
   "outputs": [],
   "source": [
    "l=cri(out1, torch.tensor(Ytrain[:, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T07:43:01.109187Z",
     "iopub.status.busy": "2023-12-11T07:43:01.108753Z",
     "iopub.status.idle": "2023-12-11T07:43:01.140921Z",
     "shell.execute_reply": "2023-12-11T07:43:01.138812Z",
     "shell.execute_reply.started": "2023-12-11T07:43:01.109153Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'l' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43ml\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'l' is not defined"
     ]
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T07:43:09.256976Z",
     "iopub.status.busy": "2023-12-11T07:43:09.256505Z",
     "iopub.status.idle": "2023-12-11T07:43:09.293041Z",
     "shell.execute_reply": "2023-12-11T07:43:09.290883Z",
     "shell.execute_reply.started": "2023-12-11T07:43:09.256941Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'l' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43ml\u001b[49m\u001b[38;5;241m.\u001b[39mbackward()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'l' is not defined"
     ]
    }
   ],
   "source": [
    "l.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada.step()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 1199979,
     "sourceId": 2005577,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30615,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
